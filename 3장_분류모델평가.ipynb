{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 정확도 Accuracy\n",
    "- 실제 데이터에서 예측 데이터가 얼마나 같은지 판단\n",
    "- 직관적인 모델 예측 성능 > 성능 왜곡 되기도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "import numpy as np\n",
    "\n",
    "# 분류기1\n",
    "class MyDummyClassifier(BaseEstimator):\n",
    "    def fit(self, X, y=None) :\n",
    "        pass\n",
    "\n",
    "    def predict(self, X) :\n",
    "        pred = np.zeros( (X.shape[0],1) )\n",
    "        for i in range(X.shape[0]) :   # sex ==1, survived =0 예측 / 아니면 1로 예측\n",
    "            if X['Sex'].iloc[i] == 1 :\n",
    "                pred[i] = 0\n",
    "            else :\n",
    "                pred[i] = 1\n",
    "\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# 전처리 함수 #\n",
    "\n",
    "# Null 처리 함수\n",
    "def fillna(df):\n",
    "    df['Age'].fillna(df['Age'].mean(), inplace=True)\n",
    "    df['Cabin'].fillna('N', inplace=True)\n",
    "    df['Embarked'].fillna('N', inplace=True)\n",
    "    df['Fare'].fillna(0, inplace=True)\n",
    "    return df\n",
    "\n",
    "# 머신러닝 알고리즘에 불필요한 피처 제거\n",
    "def drop_features(df):\n",
    "    df.drop(['PassengerId', 'Name', 'Ticket'], axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "# 레이블 인코딩 수행.\n",
    "def format_features(df):\n",
    "    df['Cabin'] = df['Cabin'].str[:1]\n",
    "    features = ['Cabin', 'Sex', 'Embarked']\n",
    "    for feature in features:\n",
    "        le = LabelEncoder()\n",
    "        le = le.fit(df[feature])\n",
    "        df[feature] = le.transform(df[feature])\n",
    "    return df\n",
    "\n",
    "# 앞에서 설정한 데이터 전처리 함수 호출\n",
    "def transform_features(df):\n",
    "    df = fillna(df)\n",
    "    df = drop_features(df)\n",
    "    df = format_features(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_15028\\773009573.py:7: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Age'].fillna(df['Age'].mean(), inplace=True)\n",
      "C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_15028\\773009573.py:8: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Cabin'].fillna('N', inplace=True)\n",
      "C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_15028\\773009573.py:9: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Embarked'].fillna('N', inplace=True)\n",
      "C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_15028\\773009573.py:10: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Fare'].fillna(0, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# data load\n",
    "titanic_df = pd.read_csv('titanic_train.csv')\n",
    "\n",
    "y_titanic_df = titanic_df['Survived']\n",
    "X_titanic_df = titanic_df.drop('Survived', axis=1)\n",
    "\n",
    "# 전처리\n",
    "X_titanic_df = transform_features(X_titanic_df)\n",
    "# 데이터셋 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_titanic_df, y_titanic_df, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 생성 & 학습\n",
    "myclf = MyDummyClassifier()\n",
    "myclf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7877094972067039"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 예측\n",
    "my_pred = myclf.predict(X_test)\n",
    "\n",
    "accuracy_score(y_test, my_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST dataset - 손글씨 데이터 셋\n",
    " - 0~9 숫자 이미지 픽셀 정보 -> 기반으로 숫자 digit 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "\n",
    "# Mnist dataset\n",
    "digits = load_digits()\n",
    "digits.data.shape  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- p.149 MyFakeClassifier 이용한 정확도 측정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 오차행렬"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 정확도 \n",
    "- 전체 맞춘 비율 = TP + TN / 전체"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[92, 18],\n",
       "       [20, 49]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# 예측기준 맞춘것 / 틀린것\n",
    "confusion_matrix(y_test, my_pred)  # row: 실제값 / col: 예측"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 정밀도, 재현율\n",
    "- 정밀도: 예측 양성 기준 정답율 = TP / TP + FP\n",
    "- 재현율: 실제 양성 기준 정답율 = TP / TP + FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7313432835820896, 0.7101449275362319)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "# 정밀도(예측 중 실제 양성 비율)    # 재현율(실제 중 실제 양성 비율)\n",
    "precision_score(y_test, my_pred) ,recall_score(y_test, my_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리 \n",
    "#X_titanic_df = transform_features(X_titanic_df)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_titanic_df, y_titanic_df, test_size=0.2, random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clf_eval(y_test, pred):\n",
    "    confusion = confusion_matrix(y_test, pred)\n",
    "    accuarcy = accuracy_score(y_test, pred)\n",
    "    precision = precision_score(y_test, pred)\n",
    "    recall = recall_score(y_test, pred)\n",
    "\n",
    "    print(confusion)\n",
    "    print('*'*20)\n",
    "    print(accuarcy, precision, recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[104  14]\n",
      " [ 13  48]]\n",
      "********************\n",
      "0.8491620111731844 0.7741935483870968 0.7868852459016393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\LG\\.conda\\envs\\ml_env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# 로지스틱회귀 분류모델 생성\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_clf = LogisticRegression()\n",
    "lr_clf.fit(X_train, y_train)\n",
    "pred = lr_clf.predict(X_test)\n",
    "\n",
    "## 정확도, 정밀도, 재현율\n",
    "get_clf_eval(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 예측 확률 값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.46185748, 0.53814252],\n",
       "       [0.87867005, 0.12132995],\n",
       "       [0.87716667, 0.12283333],\n",
       "       [0.88265168, 0.11734832],\n",
       "       [0.85511781, 0.14488219],\n",
       "       [0.88225492, 0.11774508],\n",
       "       [0.88842072, 0.11157928],\n",
       "       [0.20875208, 0.79124792],\n",
       "       [0.7827161 , 0.2172839 ],\n",
       "       [0.36954029, 0.63045971],\n",
       "       [0.89982915, 0.10017085],\n",
       "       [0.87492758, 0.12507242],\n",
       "       [0.87716068, 0.12283932],\n",
       "       [0.88837474, 0.11162526],\n",
       "       [0.43646944, 0.56353056],\n",
       "       [0.85895827, 0.14104173],\n",
       "       [0.9036873 , 0.0963127 ],\n",
       "       [0.7333301 , 0.2666699 ],\n",
       "       [0.72464827, 0.27535173],\n",
       "       [0.17177972, 0.82822028],\n",
       "       [0.75352602, 0.24647398],\n",
       "       [0.61908396, 0.38091604],\n",
       "       [0.85459213, 0.14540787],\n",
       "       [0.81471154, 0.18528846],\n",
       "       [0.88800342, 0.11199658],\n",
       "       [0.76544456, 0.23455544],\n",
       "       [0.85966954, 0.14033046],\n",
       "       [0.92588022, 0.07411978],\n",
       "       [0.71949043, 0.28050957],\n",
       "       [0.69535624, 0.30464376],\n",
       "       [0.05272145, 0.94727855],\n",
       "       [0.18268584, 0.81731416],\n",
       "       [0.87306905, 0.12693095],\n",
       "       [0.17388237, 0.82611763],\n",
       "       [0.60041003, 0.39958997],\n",
       "       [0.76544456, 0.23455544],\n",
       "       [0.92761357, 0.07238643],\n",
       "       [0.38884449, 0.61115551],\n",
       "       [0.94702986, 0.05297014],\n",
       "       [0.89608732, 0.10391268],\n",
       "       [0.64909546, 0.35090454],\n",
       "       [0.91666772, 0.08333228],\n",
       "       [0.17823687, 0.82176313],\n",
       "       [0.29210706, 0.70789294],\n",
       "       [0.36957633, 0.63042367],\n",
       "       [0.36956002, 0.63043998],\n",
       "       [0.08117001, 0.91882999],\n",
       "       [0.64173702, 0.35826298],\n",
       "       [0.05108224, 0.94891776],\n",
       "       [0.88796883, 0.11203117],\n",
       "       [0.40709188, 0.59290812],\n",
       "       [0.88837474, 0.11162526],\n",
       "       [0.86719213, 0.13280787],\n",
       "       [0.27450471, 0.72549529],\n",
       "       [0.69053835, 0.30946165],\n",
       "       [0.80314218, 0.19685782],\n",
       "       [0.77373136, 0.22626864],\n",
       "       [0.87716562, 0.12283438],\n",
       "       [0.8457624 , 0.1542376 ],\n",
       "       [0.56748279, 0.43251721],\n",
       "       [0.71978282, 0.28021718],\n",
       "       [0.89919194, 0.10080806],\n",
       "       [0.45441928, 0.54558072],\n",
       "       [0.48578854, 0.51421146],\n",
       "       [0.55571659, 0.44428341],\n",
       "       [0.90541092, 0.09458908],\n",
       "       [0.33321583, 0.66678417],\n",
       "       [0.40593831, 0.59406169],\n",
       "       [0.0481745 , 0.9518255 ],\n",
       "       [0.85183146, 0.14816854],\n",
       "       [0.87103038, 0.12896962],\n",
       "       [0.83150633, 0.16849367],\n",
       "       [0.89608507, 0.10391493],\n",
       "       [0.05198559, 0.94801441],\n",
       "       [0.80133418, 0.19866582],\n",
       "       [0.88837474, 0.11162526],\n",
       "       [0.65161929, 0.34838071],\n",
       "       [0.81631702, 0.18368298],\n",
       "       [0.16434772, 0.83565228],\n",
       "       [0.87716562, 0.12283438],\n",
       "       [0.20518192, 0.79481808],\n",
       "       [0.35487178, 0.64512822],\n",
       "       [0.06892577, 0.93107423],\n",
       "       [0.86680527, 0.13319473],\n",
       "       [0.05103334, 0.94896666],\n",
       "       [0.04958393, 0.95041607],\n",
       "       [0.8464831 , 0.1535169 ],\n",
       "       [0.87451821, 0.12548179],\n",
       "       [0.12557373, 0.87442627],\n",
       "       [0.88837474, 0.11162526],\n",
       "       [0.88837474, 0.11162526],\n",
       "       [0.76544456, 0.23455544],\n",
       "       [0.76773708, 0.23226292],\n",
       "       [0.88837474, 0.11162526],\n",
       "       [0.36956002, 0.63043998],\n",
       "       [0.92430034, 0.07569966],\n",
       "       [0.07113941, 0.92886059],\n",
       "       [0.89928971, 0.10071029],\n",
       "       [0.49451074, 0.50548926],\n",
       "       [0.0348984 , 0.9651016 ],\n",
       "       [0.49833501, 0.50166499],\n",
       "       [0.90530876, 0.09469124],\n",
       "       [0.0520388 , 0.9479612 ],\n",
       "       [0.90246542, 0.09753458],\n",
       "       [0.47005108, 0.52994892],\n",
       "       [0.87160987, 0.12839013],\n",
       "       [0.85891115, 0.14108885],\n",
       "       [0.85183176, 0.14816824],\n",
       "       [0.55031061, 0.44968939],\n",
       "       [0.89216235, 0.10783765],\n",
       "       [0.88297563, 0.11702437],\n",
       "       [0.89111067, 0.10888933],\n",
       "       [0.59652538, 0.40347462],\n",
       "       [0.34591495, 0.65408505],\n",
       "       [0.88800342, 0.11199658],\n",
       "       [0.92891769, 0.07108231],\n",
       "       [0.87564779, 0.12435221],\n",
       "       [0.80156479, 0.19843521],\n",
       "       [0.07408108, 0.92591892],\n",
       "       [0.93135647, 0.06864353],\n",
       "       [0.8883836 , 0.1116164 ],\n",
       "       [0.86915942, 0.13084058],\n",
       "       [0.93635772, 0.06364228],\n",
       "       [0.67856785, 0.32143215],\n",
       "       [0.9883526 , 0.0116474 ],\n",
       "       [0.8883836 , 0.1116164 ],\n",
       "       [0.88374782, 0.11625218],\n",
       "       [0.6832358 , 0.3167642 ],\n",
       "       [0.32239789, 0.67760211],\n",
       "       [0.67844911, 0.32155089],\n",
       "       [0.0348984 , 0.9651016 ],\n",
       "       [0.5460984 , 0.4539016 ],\n",
       "       [0.26455071, 0.73544929],\n",
       "       [0.55798029, 0.44201971],\n",
       "       [0.43004023, 0.56995977],\n",
       "       [0.64971826, 0.35028174],\n",
       "       [0.25168561, 0.74831439],\n",
       "       [0.81388088, 0.18611912],\n",
       "       [0.89605988, 0.10394012],\n",
       "       [0.19663767, 0.80336233],\n",
       "       [0.09108374, 0.90891626],\n",
       "       [0.85183176, 0.14816824],\n",
       "       [0.88196399, 0.11803601],\n",
       "       [0.8986722 , 0.1013278 ],\n",
       "       [0.90837829, 0.09162171],\n",
       "       [0.33221952, 0.66778048],\n",
       "       [0.92434545, 0.07565455],\n",
       "       [0.76622939, 0.23377061],\n",
       "       [0.08182984, 0.91817016],\n",
       "       [0.83172248, 0.16827752],\n",
       "       [0.57116768, 0.42883232],\n",
       "       [0.36880948, 0.63119052],\n",
       "       [0.363254  , 0.636746  ],\n",
       "       [0.87722131, 0.12277869],\n",
       "       [0.22214273, 0.77785727],\n",
       "       [0.11907023, 0.88092977],\n",
       "       [0.51235076, 0.48764924],\n",
       "       [0.86702847, 0.13297153],\n",
       "       [0.24828518, 0.75171482],\n",
       "       [0.30955025, 0.69044975],\n",
       "       [0.8501941 , 0.1498059 ],\n",
       "       [0.2072065 , 0.7927935 ],\n",
       "       [0.90873929, 0.09126071],\n",
       "       [0.33328345, 0.66671655],\n",
       "       [0.61959986, 0.38040014],\n",
       "       [0.34872459, 0.65127541],\n",
       "       [0.1158864 , 0.8841136 ],\n",
       "       [0.69084478, 0.30915522],\n",
       "       [0.90835899, 0.09164101],\n",
       "       [0.10690808, 0.89309192],\n",
       "       [0.88842072, 0.11157928],\n",
       "       [0.14562622, 0.85437378],\n",
       "       [0.74916838, 0.25083162],\n",
       "       [0.75963378, 0.24036622],\n",
       "       [0.59990192, 0.40009808],\n",
       "       [0.93771229, 0.06228771],\n",
       "       [0.85890413, 0.14109587],\n",
       "       [0.45498703, 0.54501297],\n",
       "       [0.37282592, 0.62717408]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 예측한 확률값 - 큰 값을 기준으로\n",
    "pred_proba = lr_clf.predict_proba(X_test)\n",
    "pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.46185748, 0.53814252, 1.        ],\n",
       "       [0.87867005, 0.12132995, 0.        ],\n",
       "       [0.87716667, 0.12283333, 0.        ],\n",
       "       [0.88265168, 0.11734832, 0.        ],\n",
       "       [0.85511781, 0.14488219, 0.        ],\n",
       "       [0.88225492, 0.11774508, 0.        ],\n",
       "       [0.88842072, 0.11157928, 0.        ],\n",
       "       [0.20875208, 0.79124792, 1.        ],\n",
       "       [0.7827161 , 0.2172839 , 0.        ],\n",
       "       [0.36954029, 0.63045971, 1.        ],\n",
       "       [0.89982915, 0.10017085, 0.        ],\n",
       "       [0.87492758, 0.12507242, 0.        ],\n",
       "       [0.87716068, 0.12283932, 0.        ],\n",
       "       [0.88837474, 0.11162526, 0.        ],\n",
       "       [0.43646944, 0.56353056, 1.        ],\n",
       "       [0.85895827, 0.14104173, 0.        ],\n",
       "       [0.9036873 , 0.0963127 , 0.        ],\n",
       "       [0.7333301 , 0.2666699 , 0.        ],\n",
       "       [0.72464827, 0.27535173, 0.        ],\n",
       "       [0.17177972, 0.82822028, 1.        ],\n",
       "       [0.75352602, 0.24647398, 0.        ],\n",
       "       [0.61908396, 0.38091604, 0.        ],\n",
       "       [0.85459213, 0.14540787, 0.        ],\n",
       "       [0.81471154, 0.18528846, 0.        ],\n",
       "       [0.88800342, 0.11199658, 0.        ],\n",
       "       [0.76544456, 0.23455544, 0.        ],\n",
       "       [0.85966954, 0.14033046, 0.        ],\n",
       "       [0.92588022, 0.07411978, 0.        ],\n",
       "       [0.71949043, 0.28050957, 0.        ],\n",
       "       [0.69535624, 0.30464376, 0.        ],\n",
       "       [0.05272145, 0.94727855, 1.        ],\n",
       "       [0.18268584, 0.81731416, 1.        ],\n",
       "       [0.87306905, 0.12693095, 0.        ],\n",
       "       [0.17388237, 0.82611763, 1.        ],\n",
       "       [0.60041003, 0.39958997, 0.        ],\n",
       "       [0.76544456, 0.23455544, 0.        ],\n",
       "       [0.92761357, 0.07238643, 0.        ],\n",
       "       [0.38884449, 0.61115551, 1.        ],\n",
       "       [0.94702986, 0.05297014, 0.        ],\n",
       "       [0.89608732, 0.10391268, 0.        ],\n",
       "       [0.64909546, 0.35090454, 0.        ],\n",
       "       [0.91666772, 0.08333228, 0.        ],\n",
       "       [0.17823687, 0.82176313, 1.        ],\n",
       "       [0.29210706, 0.70789294, 1.        ],\n",
       "       [0.36957633, 0.63042367, 1.        ],\n",
       "       [0.36956002, 0.63043998, 1.        ],\n",
       "       [0.08117001, 0.91882999, 1.        ],\n",
       "       [0.64173702, 0.35826298, 0.        ],\n",
       "       [0.05108224, 0.94891776, 1.        ],\n",
       "       [0.88796883, 0.11203117, 0.        ],\n",
       "       [0.40709188, 0.59290812, 1.        ],\n",
       "       [0.88837474, 0.11162526, 0.        ],\n",
       "       [0.86719213, 0.13280787, 0.        ],\n",
       "       [0.27450471, 0.72549529, 1.        ],\n",
       "       [0.69053835, 0.30946165, 0.        ],\n",
       "       [0.80314218, 0.19685782, 0.        ],\n",
       "       [0.77373136, 0.22626864, 0.        ],\n",
       "       [0.87716562, 0.12283438, 0.        ],\n",
       "       [0.8457624 , 0.1542376 , 0.        ],\n",
       "       [0.56748279, 0.43251721, 0.        ],\n",
       "       [0.71978282, 0.28021718, 0.        ],\n",
       "       [0.89919194, 0.10080806, 0.        ],\n",
       "       [0.45441928, 0.54558072, 1.        ],\n",
       "       [0.48578854, 0.51421146, 1.        ],\n",
       "       [0.55571659, 0.44428341, 0.        ],\n",
       "       [0.90541092, 0.09458908, 0.        ],\n",
       "       [0.33321583, 0.66678417, 1.        ],\n",
       "       [0.40593831, 0.59406169, 1.        ],\n",
       "       [0.0481745 , 0.9518255 , 1.        ],\n",
       "       [0.85183146, 0.14816854, 0.        ],\n",
       "       [0.87103038, 0.12896962, 0.        ],\n",
       "       [0.83150633, 0.16849367, 0.        ],\n",
       "       [0.89608507, 0.10391493, 0.        ],\n",
       "       [0.05198559, 0.94801441, 1.        ],\n",
       "       [0.80133418, 0.19866582, 0.        ],\n",
       "       [0.88837474, 0.11162526, 0.        ],\n",
       "       [0.65161929, 0.34838071, 0.        ],\n",
       "       [0.81631702, 0.18368298, 0.        ],\n",
       "       [0.16434772, 0.83565228, 1.        ],\n",
       "       [0.87716562, 0.12283438, 0.        ],\n",
       "       [0.20518192, 0.79481808, 1.        ],\n",
       "       [0.35487178, 0.64512822, 1.        ],\n",
       "       [0.06892577, 0.93107423, 1.        ],\n",
       "       [0.86680527, 0.13319473, 0.        ],\n",
       "       [0.05103334, 0.94896666, 1.        ],\n",
       "       [0.04958393, 0.95041607, 1.        ],\n",
       "       [0.8464831 , 0.1535169 , 0.        ],\n",
       "       [0.87451821, 0.12548179, 0.        ],\n",
       "       [0.12557373, 0.87442627, 1.        ],\n",
       "       [0.88837474, 0.11162526, 0.        ],\n",
       "       [0.88837474, 0.11162526, 0.        ],\n",
       "       [0.76544456, 0.23455544, 0.        ],\n",
       "       [0.76773708, 0.23226292, 0.        ],\n",
       "       [0.88837474, 0.11162526, 0.        ],\n",
       "       [0.36956002, 0.63043998, 1.        ],\n",
       "       [0.92430034, 0.07569966, 0.        ],\n",
       "       [0.07113941, 0.92886059, 1.        ],\n",
       "       [0.89928971, 0.10071029, 0.        ],\n",
       "       [0.49451074, 0.50548926, 1.        ],\n",
       "       [0.0348984 , 0.9651016 , 1.        ],\n",
       "       [0.49833501, 0.50166499, 1.        ],\n",
       "       [0.90530876, 0.09469124, 0.        ],\n",
       "       [0.0520388 , 0.9479612 , 1.        ],\n",
       "       [0.90246542, 0.09753458, 0.        ],\n",
       "       [0.47005108, 0.52994892, 1.        ],\n",
       "       [0.87160987, 0.12839013, 0.        ],\n",
       "       [0.85891115, 0.14108885, 0.        ],\n",
       "       [0.85183176, 0.14816824, 0.        ],\n",
       "       [0.55031061, 0.44968939, 0.        ],\n",
       "       [0.89216235, 0.10783765, 0.        ],\n",
       "       [0.88297563, 0.11702437, 0.        ],\n",
       "       [0.89111067, 0.10888933, 0.        ],\n",
       "       [0.59652538, 0.40347462, 0.        ],\n",
       "       [0.34591495, 0.65408505, 1.        ],\n",
       "       [0.88800342, 0.11199658, 0.        ],\n",
       "       [0.92891769, 0.07108231, 0.        ],\n",
       "       [0.87564779, 0.12435221, 0.        ],\n",
       "       [0.80156479, 0.19843521, 0.        ],\n",
       "       [0.07408108, 0.92591892, 1.        ],\n",
       "       [0.93135647, 0.06864353, 0.        ],\n",
       "       [0.8883836 , 0.1116164 , 0.        ],\n",
       "       [0.86915942, 0.13084058, 0.        ],\n",
       "       [0.93635772, 0.06364228, 0.        ],\n",
       "       [0.67856785, 0.32143215, 0.        ],\n",
       "       [0.9883526 , 0.0116474 , 0.        ],\n",
       "       [0.8883836 , 0.1116164 , 0.        ],\n",
       "       [0.88374782, 0.11625218, 0.        ],\n",
       "       [0.6832358 , 0.3167642 , 0.        ],\n",
       "       [0.32239789, 0.67760211, 1.        ],\n",
       "       [0.67844911, 0.32155089, 0.        ],\n",
       "       [0.0348984 , 0.9651016 , 1.        ],\n",
       "       [0.5460984 , 0.4539016 , 0.        ],\n",
       "       [0.26455071, 0.73544929, 1.        ],\n",
       "       [0.55798029, 0.44201971, 0.        ],\n",
       "       [0.43004023, 0.56995977, 1.        ],\n",
       "       [0.64971826, 0.35028174, 0.        ],\n",
       "       [0.25168561, 0.74831439, 1.        ],\n",
       "       [0.81388088, 0.18611912, 0.        ],\n",
       "       [0.89605988, 0.10394012, 0.        ],\n",
       "       [0.19663767, 0.80336233, 1.        ],\n",
       "       [0.09108374, 0.90891626, 1.        ],\n",
       "       [0.85183176, 0.14816824, 0.        ],\n",
       "       [0.88196399, 0.11803601, 0.        ],\n",
       "       [0.8986722 , 0.1013278 , 0.        ],\n",
       "       [0.90837829, 0.09162171, 0.        ],\n",
       "       [0.33221952, 0.66778048, 1.        ],\n",
       "       [0.92434545, 0.07565455, 0.        ],\n",
       "       [0.76622939, 0.23377061, 0.        ],\n",
       "       [0.08182984, 0.91817016, 1.        ],\n",
       "       [0.83172248, 0.16827752, 0.        ],\n",
       "       [0.57116768, 0.42883232, 0.        ],\n",
       "       [0.36880948, 0.63119052, 1.        ],\n",
       "       [0.363254  , 0.636746  , 1.        ],\n",
       "       [0.87722131, 0.12277869, 0.        ],\n",
       "       [0.22214273, 0.77785727, 1.        ],\n",
       "       [0.11907023, 0.88092977, 1.        ],\n",
       "       [0.51235076, 0.48764924, 0.        ],\n",
       "       [0.86702847, 0.13297153, 0.        ],\n",
       "       [0.24828518, 0.75171482, 1.        ],\n",
       "       [0.30955025, 0.69044975, 1.        ],\n",
       "       [0.8501941 , 0.1498059 , 0.        ],\n",
       "       [0.2072065 , 0.7927935 , 1.        ],\n",
       "       [0.90873929, 0.09126071, 0.        ],\n",
       "       [0.33328345, 0.66671655, 1.        ],\n",
       "       [0.61959986, 0.38040014, 0.        ],\n",
       "       [0.34872459, 0.65127541, 1.        ],\n",
       "       [0.1158864 , 0.8841136 , 1.        ],\n",
       "       [0.69084478, 0.30915522, 0.        ],\n",
       "       [0.90835899, 0.09164101, 0.        ],\n",
       "       [0.10690808, 0.89309192, 1.        ],\n",
       "       [0.88842072, 0.11157928, 0.        ],\n",
       "       [0.14562622, 0.85437378, 1.        ],\n",
       "       [0.74916838, 0.25083162, 0.        ],\n",
       "       [0.75963378, 0.24036622, 0.        ],\n",
       "       [0.59990192, 0.40009808, 0.        ],\n",
       "       [0.93771229, 0.06228771, 0.        ],\n",
       "       [0.85890413, 0.14109587, 0.        ],\n",
       "       [0.45498703, 0.54501297, 1.        ],\n",
       "       [0.37282592, 0.62717408, 1.        ]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 확률 + 예측 값 \n",
    "pred_proba_result = np.concatenate([pred_proba, pred.reshape(-1,1)], axis=1)\n",
    "pred_proba_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 이진화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[98 20]\n",
      " [10 51]]\n",
      "********************\n",
      "0.8324022346368715 0.7183098591549296 0.8360655737704918\n"
     ]
    }
   ],
   "source": [
    "# 이진화 - 기준 설정\n",
    "from sklearn.preprocessing import Binarizer\n",
    "\n",
    "custom_threshold = 0.4\n",
    "pred_proba_1 = pred_proba[:,1].reshape(-1,1)  # 새로운 예측값 - 열 하나만 꺼내기(생존)\n",
    "\n",
    "binarizer = Binarizer(threshold = custom_threshold).fit(pred_proba_1)  # 이진화\n",
    "\n",
    "custom_predict = binarizer.transform(pred_proba_1)  # 실제 값으로 변환\n",
    "\n",
    "get_clf_eval(y_test, custom_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 특이도\n",
    "- 실제 음성 기준 정답율 = TN / FP + TN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# F1-SCORE\n",
    "- 정밀도, 재현율의 조화 평균\n",
    "- 그 모델의 전체적인 성능을 볼때"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7804878048780488"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROC (Receiver Operation Characteristics)\n",
    "- 민감도 어떻게 달라지는지 보는 지표 (=재현율, 실제 양성을 맞춘 비율)\n",
    "- 거짓긍정율 = 1 - 특이도\n",
    "- 좌측 상단, 1에 가까울 수록 > 좋은 모델\n",
    "- ROC-AUC : ROC 곡선 아래 면적값, 더 클 수록 > 좋은 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.53814252, 0.12132995, 0.12283333, 0.11734832, 0.14488219,\n",
       "       0.11774508, 0.11157928, 0.79124792, 0.2172839 , 0.63045971,\n",
       "       0.10017085, 0.12507242, 0.12283932, 0.11162526, 0.56353056,\n",
       "       0.14104173, 0.0963127 , 0.2666699 , 0.27535173, 0.82822028,\n",
       "       0.24647398, 0.38091604, 0.14540787, 0.18528846, 0.11199658,\n",
       "       0.23455544, 0.14033046, 0.07411978, 0.28050957, 0.30464376,\n",
       "       0.94727855, 0.81731416, 0.12693095, 0.82611763, 0.39958997,\n",
       "       0.23455544, 0.07238643, 0.61115551, 0.05297014, 0.10391268,\n",
       "       0.35090454, 0.08333228, 0.82176313, 0.70789294, 0.63042367,\n",
       "       0.63043998, 0.91882999, 0.35826298, 0.94891776, 0.11203117,\n",
       "       0.59290812, 0.11162526, 0.13280787, 0.72549529, 0.30946165,\n",
       "       0.19685782, 0.22626864, 0.12283438, 0.1542376 , 0.43251721,\n",
       "       0.28021718, 0.10080806, 0.54558072, 0.51421146, 0.44428341,\n",
       "       0.09458908, 0.66678417, 0.59406169, 0.9518255 , 0.14816854,\n",
       "       0.12896962, 0.16849367, 0.10391493, 0.94801441, 0.19866582,\n",
       "       0.11162526, 0.34838071, 0.18368298, 0.83565228, 0.12283438,\n",
       "       0.79481808, 0.64512822, 0.93107423, 0.13319473, 0.94896666,\n",
       "       0.95041607, 0.1535169 , 0.12548179, 0.87442627, 0.11162526,\n",
       "       0.11162526, 0.23455544, 0.23226292, 0.11162526, 0.63043998,\n",
       "       0.07569966, 0.92886059, 0.10071029, 0.50548926, 0.9651016 ,\n",
       "       0.50166499, 0.09469124, 0.9479612 , 0.09753458, 0.52994892,\n",
       "       0.12839013, 0.14108885, 0.14816824, 0.44968939, 0.10783765,\n",
       "       0.11702437, 0.10888933, 0.40347462, 0.65408505, 0.11199658,\n",
       "       0.07108231, 0.12435221, 0.19843521, 0.92591892, 0.06864353,\n",
       "       0.1116164 , 0.13084058, 0.06364228, 0.32143215, 0.0116474 ,\n",
       "       0.1116164 , 0.11625218, 0.3167642 , 0.67760211, 0.32155089,\n",
       "       0.9651016 , 0.4539016 , 0.73544929, 0.44201971, 0.56995977,\n",
       "       0.35028174, 0.74831439, 0.18611912, 0.10394012, 0.80336233,\n",
       "       0.90891626, 0.14816824, 0.11803601, 0.1013278 , 0.09162171,\n",
       "       0.66778048, 0.07565455, 0.23377061, 0.91817016, 0.16827752,\n",
       "       0.42883232, 0.63119052, 0.636746  , 0.12277869, 0.77785727,\n",
       "       0.88092977, 0.48764924, 0.13297153, 0.75171482, 0.69044975,\n",
       "       0.1498059 , 0.7927935 , 0.09126071, 0.66671655, 0.38040014,\n",
       "       0.65127541, 0.8841136 , 0.30915522, 0.09164101, 0.89309192,\n",
       "       0.11157928, 0.85437378, 0.25083162, 0.24036622, 0.40009808,\n",
       "       0.06228771, 0.14109587, 0.54501297, 0.62717408])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_proba_class1 = lr_clf.predict_proba(X_test)[:, 1]\n",
    "pred_proba_class1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1573aceafd0>]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fprs, tprs, thresholds = roc_curve(y_test, pred_proba_class1)\n",
    "\n",
    "# 시각화\n",
    "plt.plot(fprs, tprs, label='ROC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC-AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.9024034454015005)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "roc_auc_score(y_test, pred_proba_class1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
